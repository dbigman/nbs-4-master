{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning II: Introduction to Supervised Classification Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL SCOPE EXERCISE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer.keys(): \n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "['malignant' 'benign']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supervised Learning Class\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "print(\"cancer.keys(): \\n{}\".format(cancer.keys()))\n",
    "print(cancer['target_names'])\n",
    "\n",
    "data = pd.DataFrame(cancer['data'], columns = cancer['feature_names'])\n",
    "target = pd.DataFrame(cancer['target'], columns = ['target'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([212, 357]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Databalance:\n",
    "import numpy as np \n",
    "\n",
    "np.unique(cancer['target'], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter and choices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection?\n",
    "# Non-transformed vs Standardization?\n",
    "# Tune the parameters of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split in Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer['data'], cancer['target'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean texture',\n",
       " 'mean smoothness',\n",
       " 'mean symmetry',\n",
       " 'mean fractal dimension',\n",
       " 'texture error',\n",
       " 'smoothness error',\n",
       " 'compactness error',\n",
       " 'concavity error',\n",
       " 'concave points error',\n",
       " 'symmetry error',\n",
       " 'fractal dimension error',\n",
       " 'worst texture',\n",
       " 'worst smoothness',\n",
       " 'worst symmetry',\n",
       " 'worst fractal dimension']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Selection\n",
    "import seaborn as sns\n",
    "#display(pd.DataFrame(X_train, columns = data.columns).corr())\n",
    "\n",
    "features = pd.DataFrame(X_train, columns = data.columns)\n",
    "target = pd.Series(y_train)\n",
    "corr_dict = {}\n",
    "cols_to_remove = []\n",
    "\n",
    "for col in list(features.columns):\n",
    "  corr_dict[col] = abs(features[col].corr(target))\n",
    "  if corr_dict[col] < 0.5:\n",
    "    cols_to_remove.append(col)\n",
    "\n",
    "#corr_dict\n",
    "cols_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"Feature Selected sets\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer['data'], \n",
    "                                                    cancer['target'], \n",
    "                                                    random_state=0)\n",
    "\n",
    "c_data = pd.DataFrame(cancer['data'], columns = cancer['feature_names'])\n",
    "c_data = c_data.drop(cols_to_remove, axis=1)\n",
    "\n",
    "X_train_featsel, X_test_featsel, y_train, y_test = train_test_split(c_data, \n",
    "                                                                    cancer['target'],\n",
    "                                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardiztion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "##### X_train #########\n",
    "# create standardization object\n",
    "scale = StandardScaler().fit(features) # \"features\" is just the training data\n",
    "\n",
    "X_train_standard = scale.transform(X_train)\n",
    "X_test_standard  = scale.transform(X_test)          \n",
    "\n",
    "X_train_standard = pd.DataFrame(X_train_standard, columns = features.columns)\n",
    "X_test_standard = pd.DataFrame(X_test_standard, columns = features.columns)\n",
    "\n",
    "##### X_train_featsel #########\n",
    "# create standardization object\n",
    "scale = StandardScaler().fit(features) # \"features\" is just the training data\n",
    "\n",
    "X_train_featsel_standard = scale.transform(X_train)\n",
    "X_test_featsel_standard = scale.transform(X_test)\n",
    "\n",
    "X_train_featsel_standard = pd.DataFrame(X_train_featsel_standard, columns = features.columns)\n",
    "X_test_featsel_standard = pd.DataFrame(X_test_featsel_standard, columns = features.columns)\n",
    "\n",
    "\n",
    "# Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "##### X_train #########\n",
    "# create standardization object\n",
    "scale = StandardScaler().fit(features)\n",
    "\n",
    "X_train_standard = scale.transform(X_train)\n",
    "X_train_standard = pd.DataFrame(X_train_standard, columns = features.columns)\n",
    "\n",
    "X_test_standard  = scale.transform(X_test)\n",
    "X_test_standard = pd.DataFrame(X_test_standard, columns = features.columns)\n",
    "\n",
    "##### X_train_featsel #########\n",
    "# create standardization object\n",
    "features_featsel = pd.DataFrame(X_train_featsel, columns = c_data.columns)\n",
    "scale = StandardScaler().fit(features_featsel)\n",
    "\n",
    "X_train_featsel_standard = scale.transform(X_train_featsel)\n",
    "X_train_featsel_standard = pd.DataFrame(X_train_featsel_standard, columns = c_data.columns)\n",
    "\n",
    "X_test_featsel_standard = scale.transform(X_test_featsel)\n",
    "X_test_featsel_standard = pd.DataFrame(X_test_featsel_standard, columns = c_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "featsel\n",
      "standard\n",
      "featsel_standard\n",
      "0.9962962962962962\n",
      "0.8321937321937322\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['normal', 'KNN', '1', 0.9480056980056981],\n",
       " ['normal', 'KNN', '3', 0.9515669515669515],\n",
       " ['normal', 'KNN', '5', 0.9514245014245015],\n",
       " ['normal', 'KNN', '7', 0.9589743589743589],\n",
       " ['normal', 'KNN', '9', 0.9588319088319087],\n",
       " ['normal', 'SVM', '0.001', 0.9628205128205127],\n",
       " ['normal', 'SVM', '0.01', 0.958119658119658],\n",
       " ['normal', 'SVM', '0.1', 0.9733618233618234],\n",
       " ['normal', 'SVM', '1', 0.9219373219373219],\n",
       " ['normal', 'SVM', '10', 0.962962962962963],\n",
       " ['featsel', 'KNN', '1', 0.9366096866096866],\n",
       " ['featsel', 'KNN', '3', 0.9401709401709402],\n",
       " ['featsel', 'KNN', '5', 0.9514245014245015],\n",
       " ['featsel', 'KNN', '7', 0.9589743589743589],\n",
       " ['featsel', 'KNN', '9', 0.9588319088319087],\n",
       " ['featsel', 'SVM', '0.001', 0.9662393162393161],\n",
       " ['featsel', 'SVM', '0.01', 0.8737891737891739],\n",
       " ['featsel', 'SVM', '0.1', 0.8321937321937322],\n",
       " ['featsel', 'SVM', '1', 0.9259259259259259],\n",
       " ['featsel', 'SVM', '10', 0.9353276353276353],\n",
       " ['standard', 'KNN', '1', nan],\n",
       " ['standard', 'KNN', '3', nan],\n",
       " ['standard', 'KNN', '5', nan],\n",
       " ['standard', 'KNN', '7', nan],\n",
       " ['standard', 'KNN', '9', nan],\n",
       " ['standard', 'SVM', '0.001', 0.9850427350427351],\n",
       " ['standard', 'SVM', '0.01', 0.9962962962962962],\n",
       " ['standard', 'SVM', '0.1', 0.9925925925925926],\n",
       " ['standard', 'SVM', '1', 0.9739316239316238],\n",
       " ['standard', 'SVM', '10', 0.9663817663817664],\n",
       " ['featsel_standard', 'KNN', '1', 0.9363247863247863],\n",
       " ['featsel_standard', 'KNN', '3', 0.9514245014245015],\n",
       " ['featsel_standard', 'KNN', '5', 0.9625356125356126],\n",
       " ['featsel_standard', 'KNN', '7', 0.9589743589743589],\n",
       " ['featsel_standard', 'KNN', '9', 0.9589743589743589],\n",
       " ['featsel_standard', 'SVM', '0.001', 0.962820512820513],\n",
       " ['featsel_standard', 'SVM', '0.01', 0.9552706552706554],\n",
       " ['featsel_standard', 'SVM', '0.1', 0.9623931623931623],\n",
       " ['featsel_standard', 'SVM', '1', 0.9665242165242166],\n",
       " ['featsel_standard', 'SVM', '10', 0.9626780626780628]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "the best model is:  ['standard', 'SVM', '0.01', 0.9962962962962962]\n"
     ]
    }
   ],
   "source": [
    "# Model Selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def model_picker(model_name, parameter):\n",
    "  if model_name == 'KNN':\n",
    "    return KNeighborsClassifier(n_neighbors = parameter)\n",
    "  if model_name == 'SVM':\n",
    "    return LinearSVC(C = parameter)\n",
    "  else:\n",
    "    raise ValueError(\"I dont know this model\")\n",
    "\n",
    "model_selection = []\n",
    "cv_tpr_list = []\n",
    "\n",
    "train_data_dict = {'normal':X_train, \n",
    "              'featsel':X_train_featsel,\n",
    "              'standard': X_train_standard,\n",
    "              'featsel_standard': X_train_featsel_standard}\n",
    "\n",
    "model_list = ['KNN', 'SVM']\n",
    "model_para = {'KNN':[1,3,5,7,9], 'SVM':[0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "for train_data_type in ['normal', 'featsel', 'standard', 'featsel_standard']:\n",
    "  train_data = train_data_dict[train_data_type]\n",
    "  print(train_data_type)\n",
    "  for model_name in model_list:\n",
    "    for p in model_para[model_name]:\n",
    "      #print(p)\n",
    "      model = model_picker(model_name, p) \n",
    "      model.fit(train_data, y_train)\n",
    "\n",
    "      cv_acc = cross_validate(model,\n",
    "                              train_data, y_train, scoring='recall',\n",
    "                              cv = 10)['test_score'].mean()\n",
    "      \n",
    "      #print(train_data_type, model_name, p, cv_acc)\n",
    "      model_selection.append([train_data_type, model_name, str(p), cv_acc])\n",
    "      cv_tpr_list.append(cv_acc)\n",
    "\n",
    "print(max(cv_tpr_list))\n",
    "print(min(cv_tpr_list))\n",
    "\n",
    "print('\\n')\n",
    "display(model_selection)\n",
    "print('\\n')\n",
    "for best in model_selection:\n",
    "  #print(best)\n",
    "  if best[3] == max(cv_acc_list):\n",
    "    print('the best model is: ', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972027972027972"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test your model\n",
    "model = model_picker('SVM', 0.01)\n",
    "model.fit(X_train_standard, y_train)\n",
    "model.score(X_test_standard, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I \"share\"/use what I just did?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer.keys(): \n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "# Supervised Learning Class\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "print(\"cancer.keys(): \\n{}\".format(cancer.keys()))\n",
    "print(cancer['target_names'])\n",
    "\n",
    "data = pd.DataFrame(cancer['data'], columns = cancer['feature_names'])\n",
    "target = pd.DataFrame(cancer['target'], columns = ['target'])\n",
    "data.head()\n",
    "\n",
    "cols_to_remove = ['mean texture', \n",
    "                'mean smoothness', \n",
    "                'mean symmetry', \n",
    "                'mean fractal dimension', \n",
    "                'texture error', \n",
    "                'smoothness error', \n",
    "                'compactness error', \n",
    "                'concavity error', \n",
    "                'concave points error', \n",
    "                'symmetry error', \n",
    "                'fractal dimension error', \n",
    "                'worst texture', \n",
    "                'worst smoothness', \n",
    "                'worst symmetry', \n",
    "                'worst fractal dimension']\n",
    "\n",
    "def model_picker(model_name, parameter):\n",
    "  if model_name == 'KNN':\n",
    "    return KNeighborsClassifier(n_neighbors = parameter)\n",
    "  if model_name == 'SVM':\n",
    "    return LinearSVC(C = parameter)\n",
    "  else:\n",
    "    raise ValueError(\"I dont know this model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns to remove are ['mean texture', 'mean smoothness', 'mean symmetry', 'mean fractal dimension', 'texture error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst texture', 'worst smoothness', 'worst symmetry', 'worst fractal dimension']\n",
      "The Standardizer we should use is: StandardScaler()\n",
      "The model we should use is:  LinearSVC(C=0.01)\n"
     ]
    }
   ],
   "source": [
    "# We need to:\n",
    "features = pd.DataFrame(cancer['data'], columns = data.columns)\n",
    "target = pd.Series(cancer['target'])\n",
    "\n",
    "# Save the preprocessing steps (feature selection and standardization):\n",
    "print(f'The columns to remove are {cols_to_remove}')\n",
    "\n",
    "# Drop the un-selected columns\n",
    "features = features.drop(cols_to_remove, axis=1)\n",
    "\n",
    "# Rebuild the Scaler with all the data\n",
    "scale = StandardScaler().fit(features)\n",
    "print(f'The Standardizer we should use is: {scale}')\n",
    "\n",
    "# Save the model (save the trained model with adjusted internal parameters in a file)\n",
    "#model = model_picker('SVM', 0.01)\n",
    "model = LinearSVC(C = 0.01)\n",
    "\n",
    "features = pd.DataFrame(scale.transform(features) , columns = features.columns) # Normalize the features before training the model\n",
    "model.fit(features, target)\n",
    "print('The model we should use is: ', model)\n",
    "# When using this we need to load the aforementioned elements\n",
    "\n",
    "######################################\n",
    "## SAVE THIS FUNCTION IN A .py FILE  or do this with another student ##\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def pre_processing(features):\n",
    "\n",
    "  # Feature Selection\n",
    "  cols_to_remove = ['mean texture', \n",
    "                  'mean smoothness', \n",
    "                  'mean symmetry', \n",
    "                  'mean fractal dimension', \n",
    "                  'texture error', \n",
    "                  'smoothness error', \n",
    "                  'compactness error', \n",
    "                  'concavity error', \n",
    "                  'concave points error', \n",
    "                  'symmetry error', \n",
    "                  'fractal dimension error', \n",
    "                  'worst texture', \n",
    "                  'worst smoothness', \n",
    "                  'worst symmetry', \n",
    "                  'worst fractal dimension']\n",
    "  \n",
    "  features = features.drop(cols_to_remove, axis=1)\n",
    "\n",
    "  # Feature Scaling\n",
    "  scale = pickle.load(open('Scaler_for_cancer.sav', 'rb'))\n",
    "  return pd.DataFrame(scale.transform(features) , columns = features.columns)\n",
    "\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the Standardizer to disk\n",
    "filename = 'Scaler_for_cancer.sav'\n",
    "pickle.dump(scale, open(filename, 'wb'))\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'Model_for_cancer.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with this, you have all the elements you need to run this again: the model, the scaler and the preprocessing code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ironhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
